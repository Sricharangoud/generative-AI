{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sricharangoud/generative-AI/blob/main/Gen_AI_5_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Design a multi-layer ANN architecture with one input, one hidden, and one output\n",
        "layer. Assume a linear activation function in the output layer and a sigmoid activation function\n",
        "in the hidden layer.\n",
        "• Write Python code for a backpropagation algorithm with gradient descent optimization to\n",
        "update weights and bias parameters of the ANN model with training data shown in Table\n",
        "1.\n",
        "• Calculate the mean square error with training and testing data shown in Table 2.\n",
        "• Write Python code that reads the input data [x1 and x2] from the user. Predict the output\n",
        "with deployed ANN model\n",
        "Tabela 1: Training Data\n",
        "x1 x2 y\n",
        "0.1 0.2 0.3432\n",
        "0.2 0.3 0.3490\n",
        "0.3 0.4 0.3548\n",
        "0.6 0.7 0.3720\n",
        "0.7 0.8 0.3776\n",
        "0.8 0.9 0.3832\n",
        "Tabela 2: Test Data\n",
        "x1 x2 y\n",
        "0.4 0.5 0.3606\n",
        "0.5 0.6 0.3663"
      ],
      "metadata": {
        "id": "7TNZoyILr-QB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)"
      ],
      "metadata": {
        "id": "QJDD0eTwukXW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 2\n",
        "hidden_size = 3\n",
        "output_size = 1\n",
        "\n",
        "hidden_weights = np.random.uniform(size=(input_size, hidden_size))\n",
        "hidden_bias = np.random.uniform(size=(1, hidden_size))\n",
        "output_weights = np.random.uniform(size=(hidden_size, output_size))\n",
        "output_bias = np.random.uniform(size=(1, output_size))"
      ],
      "metadata": {
        "id": "_EUHo_IKtbtb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_inputs = np.array([[0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9]])\n",
        "training_outputs = np.array([[0.3432], [0.3490], [0.3548], [0.3720], [0.3776], [0.3832]])\n",
        "\n",
        "test_inputs = np.array([[0.4, 0.5], [0.5, 0.6]])\n",
        "test_outputs = np.array([[0.3606], [0.3663]])\n"
      ],
      "metadata": {
        "id": "jVcRZkK0tia9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.1\n",
        "epochs = 10000\n"
      ],
      "metadata": {
        "id": "Ls398kVotmis"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    hidden_layer_activation = sigmoid(np.dot(training_inputs, hidden_weights) + hidden_bias)\n",
        "    output_layer_activation = np.dot(hidden_layer_activation, output_weights) + output_bias\n",
        "\n",
        "    error = training_outputs - output_layer_activation\n",
        "\n",
        "    d_output = error\n",
        "    d_hidden = d_output.dot(output_weights.T) * sigmoid_derivative(hidden_layer_activation)\n",
        "\n",
        "    output_weights += hidden_layer_activation.T.dot(d_output) * learning_rate\n",
        "    output_bias += np.sum(d_output, axis=0, keepdims=True) * learning_rate\n",
        "    hidden_weights += training_inputs.T.dot(d_hidden) * learning_rate\n",
        "    hidden_bias += np.sum(d_hidden, axis=0, keepdims=True) * learning_rate"
      ],
      "metadata": {
        "id": "MVTudbnZtn-N"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mse(inputs, outputs):\n",
        "    hidden_layer_activation = sigmoid(np.dot(inputs, hidden_weights) + hidden_bias)\n",
        "    output_layer_activation = np.dot(hidden_layer_activation, output_weights) + output_bias\n",
        "    mse = np.mean((outputs - output_layer_activation)**2)\n",
        "    return mse"
      ],
      "metadata": {
        "id": "lbU1650Zu1EZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_mse = calculate_mse(training_inputs, training_outputs)\n",
        "test_mse = calculate_mse(test_inputs, test_outputs)\n",
        "\n",
        "print(\"Training MSE:\", training_mse)\n",
        "print(\"Test MSE:\", test_mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtxgfXQ4u2w3",
        "outputId": "da7b23e0-59e6-4353-92f0-ab7bf2501668"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training MSE: 1.7090705527633673e-08\n",
            "Test MSE: 3.7710737965686763e-08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_output(x1, x2):\n",
        "    input_data = np.array([[x1, x2]])\n",
        "    hidden_layer_activation = sigmoid(np.dot(input_data, hidden_weights) + hidden_bias)\n",
        "    output_layer_activation = np.dot(hidden_layer_activation, output_weights) + output_bias\n",
        "    return output_layer_activation[0][0]\n"
      ],
      "metadata": {
        "id": "EID3B2O2u6yh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = float(input(\"Enter x1: \"))\n",
        "x2 = float(input(\"Enter x2: \"))\n",
        "predicted_output = predict_output(x1, x2)\n",
        "print(\"Predicted output:\", predicted_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6cnPd-Ku_oR",
        "outputId": "89e27ee4-c270-432c-f763-587889c06a5b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter x1: 0.1\n",
            "Enter x2: 0.2\n",
            "Predicted output: 0.34306265195807456\n"
          ]
        }
      ]
    }
  ]
}